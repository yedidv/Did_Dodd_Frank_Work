{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "212983865df447a587cd02ed42187f39760d467fb0227a7a0f46f8f8baf099d2"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pandas_datareader as web\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "banks_data = pd.read_excel('Banks_Data.xlsx', sheet_name='Banks_Data') \n",
    "\n",
    "unique_tickers = banks_data.drop_duplicates(subset = ['ticker'])[['ticker', 'ShortName']]\n",
    "\n",
    "def Dates(): \n",
    "    import datetime\n",
    "    ## Keep the start and end dates for this experiment in an object so it can be accessed later on \n",
    "\n",
    "    start = datetime.date(2003, 1, 1)\n",
    "    end = datetime.date(2015, 12, 31)\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " def JoinTickersWithNames(sentiment_tickers, unique_tickers): \n",
    "\n",
    "        ## Turns the tickers into a dataframe with their names, then compares the name into the banks_data names. \n",
    "\n",
    "    tickers = pd.DataFrame.from_dict(sentiment_tickers, orient = 'index',\n",
    "                                                                columns = ['YahooName']) \n",
    "    tickers.NewName = np.NaN\n",
    "    tickers = tickers.join(unique_tickers.set_index('ticker') ) \n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckTickers(data): \n",
    "    from pandas_datareader._utils import RemoteDataError\n",
    "\n",
    "    \n",
    "    good_tickers = {}\n",
    "    bad_tickers = {}\n",
    "    tickers = []\n",
    "\n",
    "    ## Return two dictionaries. One has all the tickers that work along with their full names\n",
    "    ## One has the tickers that do not work\n",
    "\n",
    "    \n",
    "\n",
    "    for ticker in data.ticker: \n",
    "        try: \n",
    "            good_tickers[ticker] = web.get_quote_yahoo(ticker).shortName.tolist()[0]\n",
    "            \n",
    "        except KeyError: \n",
    "            bad_tickers[ticker] = 'KeyError'\n",
    "            #print('KeyError in {}'.format(ticker) )\n",
    "\n",
    "        except AttributeError: \n",
    "            bad_tickers[ticker] = 'AttributeError'\n",
    "            #print('AttributeError in {}'.format(ticker))\n",
    "\n",
    "        except RemoteDataError: \n",
    "            bad_tickers[ticker] = 'RemoteDataError- No data fetched'\n",
    "            #print('Remote data error in {}'.format(ticker) ) \n",
    "\n",
    "        except IndexError: \n",
    "            bad_tickers[ticker] = 'IndexError'\n",
    "            print(ticker) \n",
    "    \n",
    "    return good_tickers, bad_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stocks(unique_tickers):  \n",
    "    import pandas_datareader as web \n",
    "    ## Use previously defined functions to return data from stock market in the defined dates. If the ticker is valid, the data is returned. \n",
    "    ## If the ticker is not valid, it goes into the bad_tickers dataframe\n",
    "    \n",
    "    ## Create two dictionaries, one with ticker symbols that work, one with ticker symbols that do not. \n",
    "    good_tickers, bad_tickers = CheckTickers(unique_tickers) \n",
    "\n",
    "    ## Return Dates\n",
    "    start, end = Dates()\n",
    "\n",
    "    ## Return the Adjusted Closing Data for the tickers that work\n",
    "    data = web.get_data_yahoo(list(good_tickers.keys()), start, end) \n",
    "    adjusted_close = data['Adj Close']\n",
    "    close = data['Close']\n",
    "\n",
    "    ## Calculate Log Returns\n",
    "    log_returns = adjusted_close.apply(lambda x: np.log10(x)).diff().iloc[1:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## Take the tickers and convert them to dataframe, compare the yahoo name with the given name from banks_data\n",
    "\n",
    "   \n",
    "\n",
    "    bad_tickers = JoinTickersWithNames(bad_tickers, unique_tickers) \n",
    "    good_tickers = JoinTickersWithNames(good_tickers, unique_tickers)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return good_tickers, bad_tickers, log_returns, adjusted_close, close\n",
    "\n",
    "good_tickers, bad_tickers, log_returns, adjusted_close, close = Stocks(unique_tickers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitGoodTickers(good_tickers, log_returns): \n",
    "\n",
    "    ## Split Stocks into dataframes of partial nulls, all nulls, or no nulls\n",
    "\n",
    "    all_nulls = log_returns[log_returns.columns[log_returns.isna().all()]].columns.tolist()\n",
    "\n",
    "\n",
    "    partial_nulls = log_returns[log_returns.columns[log_returns.isna().any()]].columns.tolist()\n",
    "    for all_null_column in all_nulls: \n",
    "        partial_nulls.remove(all_null_column)\n",
    "\n",
    "    no_nulls = log_returns[log_returns.columns[~log_returns.isna().any()]].columns.tolist()\n",
    "\n",
    "    ## Anonymous Funtion to convert values to dataframe, join with the names of the tickers, as well as the adjusted closing prices of the tickers\n",
    "    NullsToDataFrame = lambda x: pd.DataFrame(index = x).join(good_tickers).join(log_returns.transpose()).transpose()\n",
    "    all_nulls = NullsToDataFrame(all_nulls) \n",
    "    partial_nulls = NullsToDataFrame(partial_nulls) \n",
    "    no_nulls = NullsToDataFrame(no_nulls) \n",
    "\n",
    "    return all_nulls, partial_nulls, no_nulls \n",
    "\n",
    "all_nulls, partial_nulls, no_nulls = SplitGoodTickers(good_tickers, log_returns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('Returns.xlsx') as writer: \n",
    "    banks_data.to_excel(writer, sheet_name = 'Banks_Data') \n",
    "    good_tickers.to_excel(writer, sheet_name = 'Good_Tickers')\n",
    "    bad_tickers.to_excel(writer, sheet_name = 'Bad_Tickers') \n",
    "    all_nulls.to_excel(writer, sheet_name = 'All_Nulls') \n",
    "    partial_nulls.to_excel(writer, sheet_name = 'Partial_Nulls_Log_Returns') \n",
    "    no_nulls.to_excel(writer, sheet_name = 'No_Nulls_Log_Returns')\n",
    "    log_returns.to_excel(writer, sheet_name = 'Log_Returns')\n",
    "    adjusted_close.to_excel(writer, sheet_name = 'Adjusted_Closing_Prices')\n",
    "    close.to_excel(writer, sheet_name = 'Closing_Prices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}